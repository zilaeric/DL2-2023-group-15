{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduce FID and Directional loss\n",
    "Please run the notebook below to reproduce the metrics reported in the blogpost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "sys.path.append(\"../../src/lib/\")\n",
    "sys.path.append(\"../../src/lib/asyrp\")\n",
    "\n",
    "from lib_utils.metrics import DirectionalSimilarity, calculate_fid\n",
    "from transformers import (CLIPImageProcessor, CLIPTextModelWithProjection,\n",
    "                          CLIPTokenizer, CLIPVisionModelWithProjection)\n",
    "from utils.text_dic import SRC_TRG_TXT_DIC\n",
    "\n",
    "# see text in text_dic.py\n",
    "GUID = \"pixar\"\n",
    "DEVICE = \"cuda:0\"\n",
    "\n",
    "(src_texts, target_texts) = SRC_TRG_TXT_DIC[GUID]\n",
    "\n",
    "head_abl_path = Path(\"/home/parting/master_AI/DL2/DL2-2023-group-15/src/eval_runs/heads_ablation/\")\n",
    "layer_abl_path = Path(\"/home/parting/master_AI/DL2/DL2-2023-group-15/src/eval_runs/layertype_ablation/\")\n",
    "basepaths = [head_abl_path]\n",
    "results = {}\n",
    "\n",
    "clip_id = \"openai/clip-vit-large-patch14\"\n",
    "tokenizer = CLIPTokenizer.from_pretrained(clip_id)\n",
    "text_encoder = CLIPTextModelWithProjection.from_pretrained(clip_id).to(DEVICE)\n",
    "image_processor = CLIPImageProcessor.from_pretrained(clip_id)\n",
    "image_encoder = CLIPVisionModelWithProjection.from_pretrained(clip_id).to(DEVICE)\n",
    "\n",
    "dir_similarity = DirectionalSimilarity(tokenizer, text_encoder, image_processor, image_encoder)\n",
    "\n",
    "for basepath in basepaths:\n",
    "    print(f'walking from: {basepath}')\n",
    "    for path in os.walk(basepath, topdown=False):\n",
    "\n",
    "        # find ablation paths\n",
    "        if \"40/edited\" in str(path):\n",
    "\n",
    "            path = path[0] + \"/\"\n",
    "            # path magic\n",
    "            epoch = path.split(\"/40\")[0][-1]\n",
    "            if epoch != '1':\n",
    "                continue\n",
    "            ablation_type = path.split(\"eval_runs/\")[-1]\n",
    "            ablation_type = ablation_type.split(\"/40\")[0]\n",
    "            ablation_type, epoch = ablation_type[:-2], ablation_type[-1:]\n",
    "            \n",
    "            if not \"conv\" in ablation_type:\n",
    "                continue\n",
    "\n",
    "            print(f\"parsing: {path}\")\n",
    "            path_edited = path\n",
    "            path_recon = path.replace(\"edited\", \"reconstructed\")\n",
    "            path_original = path.replace(\"edited\", \"original\")\n",
    "\n",
    "            list_original_path = glob(path_original + \"/*.png\")\n",
    "\n",
    "            scores_or = []\n",
    "            scores_oe = []\n",
    "            scores_re = []\n",
    "\n",
    "            for i in range(len(list_original_path)):\n",
    "                img_original_path = str(Path(path_original) / f\"test_{i}_19_ngen40_original.png\")\n",
    "                img_reconstructed_path = str(Path(path_recon) / f\"test_{i}_19_ngen40_reconstructed.png\")\n",
    "                img_edited_path = str(Path(path_edited) / f\"test_{i}_19_ngen40_edited.png\")\n",
    "                \n",
    "                original_image = Image.open(img_original_path)\n",
    "                reconstructed_image = Image.open(img_reconstructed_path)\n",
    "                edited_image = Image.open(img_edited_path)\n",
    "                \n",
    "                similarity_score_or = dir_similarity(original_image, reconstructed_image, src_texts, src_texts)\n",
    "                similarity_score_oe = dir_similarity(original_image, edited_image, src_texts, target_texts)\n",
    "                similarity_score_re = dir_similarity(reconstructed_image, edited_image, src_texts, target_texts)\n",
    "\n",
    "                scores_or.append(float(similarity_score_or.detach().cpu()))\n",
    "                scores_oe.append(float(similarity_score_oe.detach().cpu()))\n",
    "                scores_re.append(float(similarity_score_re.detach().cpu()))\n",
    "\n",
    "            sdir_or = np.mean(scores_or)\n",
    "            sdir_or_var = np.std(scores_or)\n",
    "            sdir_oe = np.mean(scores_oe)\n",
    "            sdir_oe_var = np.std(scores_oe)\n",
    "            sdir_re = np.mean(scores_re)\n",
    "            sdir_re_var = np.std(scores_re)\n",
    "            print(\"=\" * 50)\n",
    "            print(f\"Attribute {GUID} gives original-reconstructed CLIP directional similarity: {sdir_or} ({sdir_or_var})\")\n",
    "            print(f\"Attribute {GUID} gives original-edited CLIP directional similarity: {sdir_oe}, ({sdir_oe_var})\")\n",
    "            print(f\"Attribute {GUID} gives reconstructed-edited CLIP directional similarity: {sdir_re} ({sdir_re_var}) \")\n",
    "\n",
    "            score_er = calculate_fid(path_edited, path_recon)\n",
    "            score_ro = calculate_fid(path_original, path_recon)\n",
    "            score_eo = calculate_fid(path_edited, path_original)\n",
    "            print(\"calculating FID\")\n",
    "\n",
    "            print(f\"ablation: '{ablation_type}' on epoch {epoch}, gives FID: {score_er} between edited and reconstructed\")\n",
    "            print(f\"ablation: '{ablation_type}' on epoch {epoch}, gives FID: {score_eo} between edited and original\")\n",
    "            print(f\"ablation: '{ablation_type}' on epoch {epoch}, gives FID: {score_ro} between reconstructed and original\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "            run_results = {\n",
    "                \"sdir_or\": float(sdir_or),\n",
    "                \"sdir_or_var\": float(sdir_or_var),\n",
    "                \"sdir_oe\": float(sdir_oe),\n",
    "                \"sdir_oe_var\": float(sdir_oe_var),\n",
    "                \"sdir_re\": float(sdir_re),\n",
    "                \"sdir_re_var\": float(sdir_re_var),\n",
    "                \"fid_edited_reconstructed\": score_er,\n",
    "                \"fid_edited_original\": score_eo,\n",
    "                \"fid_reconstructed_original\": score_ro,\n",
    "                \"epochs\": epoch,\n",
    "                \"ablation_name\": ablation_type,\n",
    "                \"attr\": GUID\n",
    "            }\n",
    "            \n",
    "            results[f\"{ablation_type}_{epoch}_{GUID}\"] = run_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results to json file\n",
    "with open(\"metrics.json\", \"w\") as f:\n",
    "    f.write(json.dumps(results, indent=4))\n",
    "    results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asyrp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
